{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import yfinance as yf\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai_tools import CodeInterpreterTool, FileReadTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class QueryAnalysisOutput(BaseModel):\n",
    "    \"\"\"Structured output for the query analysis task.\"\"\"\n",
    "    symbol: str = Field(..., description=\"Stock ticker symbol (e.g., TSLA, AAPL).\")\n",
    "    timeframe: str = Field(..., description=\"Time period (e.g., '1d', '1mo', '1y').\")\n",
    "    action: str = Field(..., description=\"Action to be performed (e.g., 'fetch', 'plot').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 1) Query parser agent\n",
    "query_parser_agent = Agent(\n",
    "    role=\"Stock Data Analyst\",\n",
    "    goal=\"Extract stock details and fetch required data from this user query: {query}.\",\n",
    "    backstory=\"You are a financial analyst specializing in stock market data retrieval.\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    ")\n",
    "\n",
    "query_parsing_task = Task(\n",
    "    description=\"Analyze the user query and extract stock details.\",\n",
    "    expected_output=\"A dictionary with keys: 'symbol', 'timeframe', 'action'.\",\n",
    "    output_pydantic=QueryAnalysisOutput,\n",
    "    agent=query_parser_agent,\n",
    ")\n",
    "\n",
    "\n",
    "# 2) Code writer agent\n",
    "code_writer_agent = Agent(\n",
    "    role=\"Senior Python Developer\",\n",
    "    goal=\"Write Python code to visualize stock data.\",\n",
    "    backstory=\"\"\"You are a Senior Python developer specializing in stock market data visualization. \n",
    "                 You are also a Pandas, Matplotlib and yfinance library expert.\n",
    "                 You are skilled at writing production-ready Python code\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "code_writer_task = Task(\n",
    "    description=\"\"\"Write Python code to visualize stock data based on the inputs from the stock analyst\n",
    "                   where you would find stock symbol, timeframe and action.\"\"\",\n",
    "    expected_output=\"A clean and executable Python script file (.py) for stock visualization.\",\n",
    "    agent=code_writer_agent,\n",
    ")\n",
    "\n",
    "\n",
    "# 3) Code interpreter agent (uses code interpreter tool from crewai)\n",
    "code_interpreter_tool = CodeInterpreterTool()\n",
    "\n",
    "code_execution_agent = Agent(\n",
    "    role=\"Senior Code Execution Expert\",\n",
    "    goal=\"Review and execute the generated Python code by code writer agent to visualize stock data.\",\n",
    "    backstory=\"You are a code execution expert. You are skilled at executing Python code.\",\n",
    "    # tools=[code_interpreter_tool],\n",
    "    allow_code_execution=True,   # This automatically adds the CodeInterpreterTool\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "code_execution_task = Task(\n",
    "    description=\"\"\"Review and execute the generated Python code by code writer agent to visualize stock data.\"\"\",\n",
    "    expected_output=\"A clean and executable Python script file (.py) for stock visualization.\",\n",
    "    agent=code_execution_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mStock Data Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the user query and extract stock details.\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/home/abhishek/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-1.5-flash\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m crew \u001b[38;5;241m=\u001b[39m Crew(\n\u001b[1;32m      2\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[query_parser_agent, code_writer_agent, code_execution_agent],\n\u001b[1;32m      3\u001b[0m     tasks\u001b[38;5;241m=\u001b[39m[query_parsing_task, code_writer_task, code_execution_task],\n\u001b[1;32m      4\u001b[0m     process\u001b[38;5;241m=\u001b[39mProcess\u001b[38;5;241m.\u001b[39msequential\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run the crew with an example query\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m crew\u001b[38;5;241m.\u001b[39mkickoff(inputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlot YTD stock gain of Tesla\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/crew.py:659\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_crew_planning()\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 659\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sequential_process()\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    661\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/crew.py:768\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_tasks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/crew.py:871\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    868\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    870\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 871\u001b[0m task_output \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mexecute_sync(\n\u001b[1;32m    872\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent_to_use,\n\u001b[1;32m    873\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    874\u001b[0m     tools\u001b[38;5;241m=\u001b[39mcast(List[BaseTool], tools_for_task),\n\u001b[1;32m    875\u001b[0m )\n\u001b[1;32m    876\u001b[0m task_outputs\u001b[38;5;241m.\u001b[39mappend(task_output)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/task.py:351\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    346\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    347\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    348\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_core(agent, context, tools)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/task.py:499\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    498\u001b[0m crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e), task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/task.py:415\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[1;32m    414\u001b[0m crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context\u001b[38;5;241m=\u001b[39mcontext, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 415\u001b[0m result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mexecute_task(\n\u001b[1;32m    416\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    418\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    419\u001b[0m )\n\u001b[1;32m    421\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    422\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    423\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    424\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    431\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agent.py:435\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    429\u001b[0m         event\u001b[38;5;241m=\u001b[39mAgentExecutionErrorEvent(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m         ),\n\u001b[1;32m    434\u001b[0m     )\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agent.py:411\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    407\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_with_timeout(\n\u001b[1;32m    408\u001b[0m             task_prompt, task, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_execution_time\n\u001b[1;32m    409\u001b[0m         )\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_without_timeout(task_prompt, task)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m         event\u001b[38;5;241m=\u001b[39mAgentExecutionErrorEvent(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m         ),\n\u001b[1;32m    422\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agent.py:507\u001b[0m, in \u001b[0;36mAgent._execute_without_timeout\u001b[0;34m(self, task_prompt, task)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute_without_timeout\u001b[39m(\u001b[38;5;28mself\u001b[39m, task_prompt: \u001b[38;5;28mstr\u001b[39m, task: Task) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a task without a timeout.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m        The output of the agent.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    508\u001b[0m         {\n\u001b[1;32m    509\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_prompt,\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names,\n\u001b[1;32m    511\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description,\n\u001b[1;32m    512\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mhuman_input,\n\u001b[1;32m    513\u001b[0m         }\n\u001b[1;32m    514\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:121\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    118\u001b[0m handle_unknown_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer, e)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:110\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    113\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    114\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:206\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_context_length_exceeded(e):\n\u001b[1;32m    208\u001b[0m         handle_context_length(\n\u001b[1;32m    209\u001b[0m             respect_context_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrespect_context_window,\n\u001b[1;32m    210\u001b[0m             printer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m             i18n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i18n,\n\u001b[1;32m    215\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:153\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m handle_max_iterations_exceeded(\n\u001b[1;32m    143\u001b[0m         formatted_answer,\n\u001b[1;32m    144\u001b[0m         printer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    151\u001b[0m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit)\n\u001b[0;32m--> 153\u001b[0m answer \u001b[38;5;241m=\u001b[39m get_llm_response(\n\u001b[1;32m    154\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm,\n\u001b[1;32m    155\u001b[0m     messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m    156\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    157\u001b[0m     printer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer,\n\u001b[1;32m    158\u001b[0m )\n\u001b[1;32m    159\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m process_llm_response(answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_stop_words)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# Extract agent fingerprint if available\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:160\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    157\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     )\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[1;32m    162\u001b[0m     printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    163\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:151\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     answer \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    152\u001b[0m         messages,\n\u001b[1;32m    153\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    157\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/llm.py:956\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_streaming_response(\n\u001b[1;32m    953\u001b[0m             params, callbacks, available_functions\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 956\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_non_streaming_response(\n\u001b[1;32m    957\u001b[0m             params, callbacks, available_functions\n\u001b[1;32m    958\u001b[0m         )\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LLMContextLengthExceededException:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Re-raise LLMContextLengthExceededException as it should be handled\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# by the CrewAgentExecutor._invoke_loop method, which can then decide\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# whether to summarize the content or abort based on the respect_context_window flag\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/crewai/llm.py:768\u001b[0m, in \u001b[0;36mLLM._handle_non_streaming_response\u001b[0;34m(self, params, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# --- 1) Make the completion call\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# Attempt to make the completion call, but catch context window errors\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# and convert them to our own exception type for consistent handling\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# across the codebase. This allows CrewAgentExecutor to handle context\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# length issues appropriately.\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m     response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;66;03m# Convert litellm's context window error to our own exception type\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;66;03m# for consistent handling in the rest of the codebase\u001b[39;00m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededException(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/utils.py:1283\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1280\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1281\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1282\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/utils.py:1161\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m-> 1161\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1162\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/main.py:3241\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3240\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   3242\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   3243\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   3244\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   3245\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   3246\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   3247\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/main.py:1039\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     model \u001b[38;5;241m=\u001b[39m deployment_id\n\u001b[1;32m   1038\u001b[0m     custom_llm_provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1039\u001b[0m model, custom_llm_provider, dynamic_api_key, api_base \u001b[38;5;241m=\u001b[39m get_llm_provider(\n\u001b[1;32m   1040\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1041\u001b[0m     custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   1042\u001b[0m     api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   1043\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1044\u001b[0m )\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1047\u001b[0m     provider_specific_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m provider_specific_header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_llm_provider\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m custom_llm_provider\n\u001b[1;32m   1049\u001b[0m ):\n\u001b[1;32m   1050\u001b[0m     headers\u001b[38;5;241m.\u001b[39mupdate(provider_specific_header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py:373\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBadRequestError):\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m         error_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    376\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetLLMProvider Exception - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124moriginal model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py:350\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m     error_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Pass model as E.g. For \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuggingface\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m inference endpoints pass in `completion(model=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuggingface/starcoder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# maps to openai.NotFoundError, this is raised when openai does not recognize the llm\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBadRequestError(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    351\u001b[0m         message\u001b[38;5;241m=\u001b[39merror_str,\n\u001b[1;32m    352\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    353\u001b[0m         response\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mResponse(\n\u001b[1;32m    354\u001b[0m             status_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m    355\u001b[0m             content\u001b[38;5;241m=\u001b[39merror_str,\n\u001b[1;32m    356\u001b[0m             request\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mRequest(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/BerriAI/litellm\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         ),\n\u001b[1;32m    358\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     )\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_base, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi base needs to be a string. api_base=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(api_base)\n\u001b[1;32m    363\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-1.5-flash\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
     ]
    }
   ],
   "source": [
    "\n",
    "crew = Crew(\n",
    "    agents=[query_parser_agent, code_writer_agent, code_execution_agent],\n",
    "    tasks=[query_parsing_task, code_writer_task, code_execution_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "# Run the crew with an example query\n",
    "result = crew.kickoff(inputs={\"query\": \"Plot YTD stock gain of Tesla\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mraw)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(result.raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
